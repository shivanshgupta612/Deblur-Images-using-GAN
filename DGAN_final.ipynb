{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1hk6aB4o7CB",
        "outputId": "ed023e99-9375-46d5-f818-d10463551b1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Deblur-Images-using-GAN' already exists and is not an empty directory.\n",
            "TensorFlow 1.x selected.\n",
            "/content/Deblur-Images-using-GAN\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/theadityakr/Deblur-Images-using-GAN.git\n",
        "import os\n",
        "os.chdir(\"Deblur-Images-using-GAN/\")\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhlF_DlVo7CH"
      },
      "source": [
        "#### Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-4aXbjxo7CK",
        "outputId": "fbeec45a-441f-4e5c-c442-ef13209c52df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.7/dist-packages (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.21.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.15.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import glob, cv2, os\n",
        "import datetime\n",
        "import tqdm\n",
        "\n",
        "!pip install h5py==2.10.0\n",
        "\n",
        "#from deblurgan.utils import write_log\n",
        "from losses import wasserstein_loss, perceptual_loss\n",
        "from model import generator_model, discriminator_model, generator_containing_discriminator_multiple_outputs\n",
        "\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.optimizers import Adam\n",
        "#for saving weights\n",
        "BASE_DIR = 'weights/'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dptGpaTco7CN"
      },
      "outputs": [],
      "source": [
        "# Read images from input directory\n",
        "def load_images(images_path):\n",
        "    X_images = []\n",
        "    for img in images_path:\n",
        "      X_images.append(cv2.resize(cv2.imread(img), input_shape[:-1]))\n",
        "    X_images = np.array(X_images)\n",
        "    #Preprocessing i.e normalizing data\n",
        "    X_images = (X_images - 127.5) / 127.5\n",
        "    return X_images\n",
        "\n",
        "# Saving weights after each iteration\n",
        "def save_all_weights(d, g, epoch_number, current_loss):\n",
        "    now = datetime.datetime.now()\n",
        "    save_dir = os.path.join(BASE_DIR, '{}{}'.format(now.month, now.day))\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "    g.save_weights(os.path.join(save_dir, 'generator_{}_{}.h5'.format(epoch_number, current_loss)), True)\n",
        "    d.save_weights(os.path.join(save_dir, 'discriminator_{}.h5'.format(epoch_number)), True)\n",
        "\n",
        "# Training of model\n",
        "def train_multiple_outputs(images_path, batch_size, epoch_num, critic_updates=5):\n",
        "    x_path = glob.glob(images_path + \"/blurred/*\")\n",
        "    y_path = glob.glob(images_path + \"/unblurred/*\")\n",
        "    x_path.sort(); y_path.sort();\n",
        "    x_train = load_images(x_path)\n",
        "    y_train = load_images(y_path)\n",
        "\n",
        "    g = generator_model(input_shape)\n",
        "    d = discriminator_model(input_shape)\n",
        "    d_on_g = generator_containing_discriminator_multiple_outputs(g, d, input_shape)\n",
        "\n",
        "    d_opt = Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
        "    d_on_g_opt = Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
        "\n",
        "    d.trainable = True\n",
        "    d.compile(optimizer=d_opt, loss=wasserstein_loss)\n",
        "    d.trainable = False\n",
        "    loss = [perceptual_loss, wasserstein_loss]\n",
        "    loss_weights = [100, 1]\n",
        "    d_on_g.compile(optimizer=d_on_g_opt, loss=loss, loss_weights=loss_weights)\n",
        "    d.trainable = True\n",
        "\n",
        "    output_true_batch, output_false_batch = np.ones((batch_size, 1)), -np.ones((batch_size, 1))\n",
        "\n",
        "    tensorboard_callback = TensorBoard(\"../\")\n",
        "    print(\"returning\")\n",
        "\n",
        "    for epoch in tqdm.tqdm(range(epoch_num)):\n",
        "        permutated_indexes = np.random.permutation(x_train.shape[0])\n",
        "\n",
        "        d_losses = []\n",
        "        d_on_g_losses = []\n",
        "        for index in range(int(x_train.shape[0] / batch_size)):\n",
        "            batch_indexes = permutated_indexes[index*batch_size:(index+1)*batch_size]\n",
        "            image_blur_batch = x_train[batch_indexes]\n",
        "            image_full_batch = y_train[batch_indexes]\n",
        "\n",
        "            generated_images = g.predict(x=image_blur_batch, batch_size=batch_size)\n",
        "\n",
        "            for _ in range(critic_updates):\n",
        "                d_loss_real = d.train_on_batch(image_full_batch, output_true_batch)\n",
        "                d_loss_fake = d.train_on_batch(generated_images, output_false_batch)\n",
        "                d_loss = 0.5 * np.add(d_loss_fake, d_loss_real)\n",
        "                d_losses.append(d_loss)\n",
        "\n",
        "            d.trainable = False\n",
        "\n",
        "            d_on_g_loss = d_on_g.train_on_batch(image_blur_batch, [image_full_batch, output_true_batch])\n",
        "            d_on_g_losses.append(d_on_g_loss)\n",
        "\n",
        "            d.trainable = True\n",
        "\n",
        "        # write_log(tensorboard_callback, ['g_loss', 'd_on_g_loss'], [np.mean(d_losses), np.mean(d_on_g_losses)], epoch_num)\n",
        "        print(np.mean(d_losses), np.mean(d_on_g_losses))\n",
        "        with open('log.txt', 'a+') as f:\n",
        "            f.write('{} - {} - {}\\n'.format(epoch, np.mean(d_losses), np.mean(d_on_g_losses)))\n",
        "\n",
        "        save_all_weights(d, g, epoch, int(np.mean(d_on_g_losses)))\n",
        "    return\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhHD-mmUo7CS"
      },
      "source": [
        "#### Set Parameters accordingly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "U8QkFgD-o7CU"
      },
      "outputs": [],
      "source": [
        "# Setting parameters for our model\n",
        "input_shape = (256,256,3)\n",
        "batch_size = 1\n",
        "epochs = 1\n",
        "input_directory = \"train_data\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Np1GkxRTo7CV"
      },
      "source": [
        "#### Training of model with the parameters provided above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIksx0Who7CY",
        "outputId": "0c2e0fed-d4fb-47ad-ad07-075e0b317b8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 3s 0us/step\n",
            "returning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.4339799720854823 1764.1526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [11:30<00:00, 690.89s/it]\n"
          ]
        }
      ],
      "source": [
        "train_multiple_outputs(input_directory, batch_size, epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "Fqt9GVDSr3C5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "oggyhrQzo7Ca"
      },
      "outputs": [],
      "source": [
        "from model import generator_model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to read images from input directory\n",
        "def load_images(images_path):\n",
        "    X_images = []\n",
        "    for img in images_path:\n",
        "      X_images.append(cv2.resize(cv2.imread(img), input_shape[:-1]))\n",
        "    X_images = np.array(X_images)\n",
        "    #Preprocessing i.e normalizing data\n",
        "    X_images = (X_images - 127.5) / 127.5        \n",
        "    return X_images\n",
        "\n",
        "#Creating an instant of model from weight file provided\n",
        "def test(input_dir, model, output_dir):\n",
        "    images_path = glob.glob(input_dir + \"/*\")\n",
        "    data = load_images(images_path)\n",
        "    g = generator_model(input_shape)\n",
        "    g.load_weights(model)\n",
        "    generated_images = g.predict(data, batch_size=batch_size)\n",
        "    #deprocessing i.e. un normalize\n",
        "    generated_images = (generated_images * 127.5 + 127.5).astype('uint8')\n",
        "    data = (data * 127.5 + 127.5).astype('uint8')\n",
        "    for i in range(generated_images.shape[0]):\n",
        "        output = np.concatenate((data[i,:,:,:],generated_images[i, :, :, :]), axis=1)\n",
        "        img_name = output_dir + \"/\" + os.path.basename(images_path[i])\n",
        "        cv2.imwrite(img_name,output)\n"
      ],
      "metadata": {
        "id": "5i3N37KDsHRU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/output\"\n",
        "if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "# Setting parameters for our model\n",
        "input_shape = (256,256,3)\n",
        "batch_size = 1\n",
        "input_directory = \"test_data/blurred\"\n",
        "model_weights = \"generator.h5\"\n",
        "output_directory = \"/content/output\""
      ],
      "metadata": {
        "id": "Kd8btgnPsJnQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(input_directory, model_weights, output_directory)"
      ],
      "metadata": {
        "id": "o1A4tSNysLvK"
      },
      "execution_count": 9,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "hassan",
      "language": "python",
      "name": "hassan"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "DGAN_final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}